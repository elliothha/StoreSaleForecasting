{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b31cb86-a4d1-4de9-918b-88db355364a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326992ad-3e43-4d25-a4b5-96f7b6c4dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9396ac32-0635-4e76-991c-7316e56380a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c0cf2d-0af5-4c53-9638-7452b20d76a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# Transformer Specific Hyperparams\n",
    "forward_expansion = 4\n",
    "output_dim = 1\n",
    "model_dim = 512\n",
    "num_heads = 8\n",
    "n_enc = 15\n",
    "n_dec = 1\n",
    "# num_layers = 6\n",
    "\n",
    "# LSTM Specific Hyperparams\n",
    "num_layers = 3\n",
    "num_features = 3\n",
    "hidden_dim = 128\n",
    "\n",
    "# Data Hyperparams\n",
    "seq_len = 15 \n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "# Model Hyperparams\n",
    "lr = 0.001\n",
    "decay = 0\n",
    "factor = 0.1\n",
    "dropout = 0.1\n",
    "optimizer_name = 'Adam'\n",
    "scheduler_name = 'MultiStepLR'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eca201f-35b1-409b-bc8d-db2d76bb7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(optimizer_name, model, **kwargs):\n",
    "    if optimizer_name=='Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=kwargs['lr'])\n",
    "    elif optimizer_name=='SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(),lr=kwargs['lr'],momentum=kwargs['momentum'], weight_decay=kwargs['weight_decay'])\n",
    "    else:\n",
    "        raise ValueError('Not valid optimizer name')\n",
    "    return optimizer\n",
    "    \n",
    "def make_scheduler(scheduler_name, optimizer, **kwargs):\n",
    "    if scheduler_name=='MultiStepLR':\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=kwargs['milestones'],gamma=kwargs['factor'])\n",
    "    else:\n",
    "        raise ValueError('Not valid scheduler name')\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6929940f-ef5c-4a36-b342-8d34221585f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b717949-d1eb-4304-8f33-b68fae0e79c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load & Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b9761-4c53-4755-95e3-a8cac1b765ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_df = pd.read_csv('data/oil.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "\n",
    "# set date entries to DateTimes\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "test_df['date'] = pd.to_datetime(test_df['date'])\n",
    "oil_df['date'] = pd.to_datetime(oil_df['date'])\n",
    "\n",
    "# merge oil df with train and test df based on date values\n",
    "train_df = train_df.merge(oil_df, on='date', how='left')\n",
    "train_df['dcoilwtico'] = train_df['dcoilwtico'].interpolate(limit_direction='both')\n",
    "\n",
    "test_df = test_df.merge(oil_df, on='date', how='left')\n",
    "test_df['dcoilwtico'] = test_df['dcoilwtico'].interpolate(limit_direction='both')\n",
    "\n",
    "train_df = train_df.set_index('id')\n",
    "test_df = test_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8abc28c-64b2-413d-8a70-896aaa5026f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique categories for both categorical features\n",
    "store_nbrs = sorted(train_df['store_nbr'].unique())\n",
    "families = sorted(train_df['family'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa08ac15-bcd3-4c7f-bf0a-1c30e5de35cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper Functions for Subset Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62aadf6-7aa9-47ed-adcf-5f50dbfc68a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subset(store_nbr, family, df):\n",
    "    '''Creates subset DataFrame from df with all data corresponding to store_nbr and family, and dates\n",
    "        \n",
    "    Args:\n",
    "        store_nbr: Current store_nbr\n",
    "        family: Current family\n",
    "        df: Original training or testing dataframe \n",
    "            \n",
    "    Returns:\n",
    "        dates: subset dates used for later indexing with predicted testing data\n",
    "        subset_df: DataFrame with all continuous data corresponding to store_nbr and family\n",
    "    '''\n",
    "    \n",
    "    # gets all rows from input df corresponding to the specific store_nbr and family combination \n",
    "    subset_df = df[(df['store_nbr'] == store_nbr) & (df['family'] == family)]\n",
    "    dates = subset_df['date']\n",
    "    \n",
    "    # adds sales column in case using testing data\n",
    "    if 'sales' not in subset_df:\n",
    "        subset_df.insert(loc=0, column='sales', value=0.0)\n",
    "    \n",
    "    # set date as index and fill in missing dates for the (store_nbr, family) combination with zeros\n",
    "    if 'date' in subset_df:\n",
    "        df = df.set_index('date')\n",
    "        subset_df = subset_df.set_index('date')\n",
    "        date_range = pd.date_range(start=df.index.min(), end=df.index.max())\n",
    "        subset_df = subset_df.reindex(date_range)\n",
    "        \n",
    "        # Fill non-'dcoilwtico' columns with 0\n",
    "        for col in subset_df.columns:\n",
    "            if col != 'dcoilwtico':\n",
    "                subset_df[col].fillna(0, inplace=True)\n",
    "\n",
    "        # Interpolate 'dcoilwtico' column\n",
    "        subset_df[\"dcoilwtico\"] = subset_df[\"dcoilwtico\"].interpolate(limit_direction=\"both\")\n",
    "    \n",
    "    # drop store_nbr and family columns\n",
    "    if 'store_nbr' in subset_df and 'family' in subset_df:\n",
    "        subset_df = subset_df.drop(columns=['store_nbr', 'family'])\n",
    "    \n",
    "    # dates = (num_entries, 1) col is date\n",
    "    # subset_df = (num_entries, num_features) cols are continuous features: sales, onpromotion, dcoilwtico\n",
    "    return dates, subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c086b98-6fe1-4281-8fb8-5c3c8e7f0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df):\n",
    "    '''Creates sequence data for DataFrame indexed on continuous time steps\n",
    "        \n",
    "    Args:\n",
    "        df: Subset DataFrame for current (store_nbr, family) combination\n",
    "            \n",
    "    Returns:\n",
    "        X: numpy array of all of the sequences made from df\n",
    "            shape = (num_sequences, seq_len, num_features)\n",
    "        y: numpy array of the single scalar value of sales number from day after sequence ends\n",
    "            shape = (num_sequences, )\n",
    "    '''\n",
    "    X, y = [], []\n",
    "    \n",
    "    for idx in range(len(df) - seq_len):\n",
    "        # seq_x = (seq_len, num_features)\n",
    "        seq_x = df.iloc[idx:idx+seq_len].values\n",
    "        X.append(seq_x)\n",
    "        \n",
    "        if 'sales' in df:\n",
    "            # seq_y = scalar value of sales number from day after sequence ends\n",
    "            seq_y = df.iloc[idx + seq_len]['sales']\n",
    "            y.append(seq_y)\n",
    "    \n",
    "    # Convert the list of sequences to a numpy array and ensure the data type is float32\n",
    "    X = np.stack(X).astype(np.float32)\n",
    "    y = np.array(y, dtype=np.float32)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d871046-fe29-4a98-9f88-6d0c1dcb53c5",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e43b99-7cf6-4a22-ba86-2e591a6c0bb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RMSLE Loss Function Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d27d4-506d-450c-963e-6044ce0ea27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSLELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSLELoss, self).__init__()\n",
    "\n",
    "    def forward(self, predicted, actual):\n",
    "        \"\"\"Computes the Root Mean Squared Logarithmic Error\n",
    "\n",
    "        Args:\n",
    "            predicted: The predicted values in tensor form\n",
    "            actual: The actual target values in tensor form\n",
    "\n",
    "        Returns:\n",
    "            loss: The RMSLE loss in tensor form\n",
    "        \"\"\"\n",
    "        # Ensure that predicted and actual are positive and non-zero\n",
    "        predicted = torch.clamp(predicted, min=1e-6)\n",
    "        actual = torch.clamp(actual, min=1e-6)\n",
    "\n",
    "        # Calculate the squared logarithmic error\n",
    "        log_error = torch.log(predicted + 1) - torch.log(actual + 1)\n",
    "        squared_log_error = torch.square(log_error)\n",
    "\n",
    "        # Calculate the mean of the squared log error\n",
    "        mean_squared_log_error = torch.mean(squared_log_error)\n",
    "\n",
    "        # Return the square root of the mean squared log error\n",
    "        loss = torch.sqrt(mean_squared_log_error)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a5f3b-da3f-45ea-a39b-b148a8bcb3e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transformer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a94ad79-df98-4c0b-99f6-eb014b847823",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, model_dim, num_heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "        self.model_dim = model_dim # D\n",
    "        self.num_heads = num_heads # H\n",
    "        self.head_dim = model_dim // num_heads # D/H = int division\n",
    "\n",
    "        self.values = nn.Linear(in_features=self.model_dim, out_features=self.model_dim, bias=False)\n",
    "        self.keys = nn.Linear(in_features=self.model_dim, out_features=self.model_dim, bias=False)\n",
    "        self.queries = nn.Linear(in_features=self.model_dim, out_features=self.model_dim, bias=False)\n",
    "\n",
    "        self.fc_out = nn.Linear(self.num_heads*self.head_dim, self.model_dim)\n",
    "\n",
    "    def forward(self, values, keys, query, mask=None):\n",
    "        batch_size = query.shape[0]\n",
    "        # For encoder: v, k, q = out, out, out = (B, N_enc, D)\n",
    "        # For masked mha: v, k, q = x, x, x = (B, N_dec, D)\n",
    "        # For encoder-decoder mha: v, k = enc, enc = (B, N_enc, D), q = x = (B, N_dec, D)\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "\n",
    "        # send to Linear Layer to get into head_dim space\n",
    "        # For encoder: v, k, q = (B, N_enc, D/H)\n",
    "        # For masked mha: v, k, q = (B, N_dec, D/H)\n",
    "        # For enc-dec mha: v, k = (B, N_enc, D/H), q = (B, N_dec, D/H)\n",
    "        values = self.values(values)\n",
    "        keys = self.keys(keys)\n",
    "        queries = self.queries(query)\n",
    "\n",
    "        # split embedding into self.heads pieces\n",
    "        # For encoder: v, k, q = (B, H, N_enc, D/H)\n",
    "        # For masked mha: v, k, q = (B, H, N_dec, D/H)\n",
    "        # For enc-dec mha: v, k = (B, H, N_enc, D/H), q = (B, H, N_dec, D/H)\n",
    "        values = values.reshape(batch_size, self.num_heads, value_len, self.head_dim)\n",
    "        keys = keys.reshape(batch_size, self.num_heads, key_len, self.head_dim)\n",
    "        queries = query.reshape(batch_size, self.num_heads, query_len, self.head_dim)\n",
    "\n",
    "        # Calculate energy = Q @ K.T\n",
    "        # For encoder: q, k = (B, H, N_enc, D/H) -> energy = (B, H, N_enc, N_enc)\n",
    "        # For masked mha: q, k = (B, H, N_dec, D/H) -> energy = (B, H, N_dec, N_dec)\n",
    "        # For enc-dec mha: q = (B, H, N_dec, D/H), k = (B, H, N_enc, D/H) -> energy = (B, H, N_dec, N_enc)\n",
    "        energy = torch.einsum('bhqd,bhkd->bhqk', [queries, keys])\n",
    "\n",
    "        # mask for masked mha decoder = (B, H, N_dec, N_dec)\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, float('-1e20'))\n",
    "\n",
    "        # A = softmax((Q @ K.T)/sqrt(d_K))\n",
    "        # dim=3 means we normalize across 3rd dim=key_len\n",
    "        # same dims as energy step\n",
    "        attention = torch.softmax(energy / (self.model_dim ** (1/2)), dim=3)\n",
    "\n",
    "        # For encoder: a = (B, H, N_enc, N_enc), v = (B, H, N_enc, D/H)\n",
    "        # -> out = (B D) -> reshape into out = (B, N_enc, H*D/H) = (B, N_enc, D)\n",
    "        # For masked mha: a = (B, H, N_dec, N_dec), v = (B, H, N_dec, D/H)\n",
    "        # -> out = (B, H, N_dec, D) -> reshape into out = (B, N_dec, H*D/H) = (B, N_dec, D)\n",
    "        # For enc-dec mha: a = (B, H, N_dec, N_enc), v = (B, H, N_enc, D/H)\n",
    "        # -> out = (B, H, N_dec, D) -> reshape into out = (B, N_dec, H*D/H) = (B, N_dec, D)\n",
    "        out = torch.einsum('bhav,bhvd->bhad', [attention, values]).reshape(\n",
    "            batch_size, query_len, self.num_heads*self.head_dim\n",
    "        )\n",
    "\n",
    "        # send to Linear Layer output is (B, query_len, model_dim)\n",
    "        # For encoder: out = (B, N_enc, D)\n",
    "        # For masked mha: out = (B, N_dec, D)\n",
    "        # For enc-dec mha: out = (B, N_dec, D)\n",
    "        out = self.fc_out(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, model_dim, num_heads, forward_expansion, dropout):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "\n",
    "        self.attention = SelfAttention(model_dim=model_dim, num_heads=num_heads)\n",
    "        # normalizes over last dim, D\n",
    "        self.norm1 = nn.LayerNorm(normalized_shape=model_dim)\n",
    "        self.norm2 = nn.LayerNorm(normalized_shape=model_dim)\n",
    "\n",
    "        # forward_expansion = 4 for 4*512=2048\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(in_features=model_dim, out_features=forward_expansion*model_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=forward_expansion*model_dim, out_features=model_dim)\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, value, key, query):\n",
    "        # Multi-Head Attention + Add & Norm Block\n",
    "        # attention = (B, N_enc, D)\n",
    "        attention = self.attention(value, key, query)\n",
    "        # adding query represents the skip connection\n",
    "        # query = (B, N_enc, D)\n",
    "        # x = (B, N_enc, D)\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "\n",
    "        # Feed Forward + Add & Norm Block\n",
    "        # forward = (B, N_enc, D)\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "\n",
    "        # out = (B, N_enc, D)\n",
    "        return out\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_dim,\n",
    "            num_layers,\n",
    "            num_heads,\n",
    "            device,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            n_enc,\n",
    "            num_features\n",
    "    ):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.linear = nn.Linear(in_features=num_features, out_features=model_dim)\n",
    "        self.position_embedding = nn.Embedding(num_embeddings=n_enc, embedding_dim=model_dim)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                EncoderBlock(\n",
    "                    model_dim=model_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    forward_expansion=forward_expansion,\n",
    "                    dropout=dropout\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input, x = (batch_size, N_enc=15, num_features=3) = (B, N_enc, 3)\n",
    "        batch_size, N_enc, num_features = x.shape\n",
    "        # positions = (N_enc) -> (B, N_enc)\n",
    "        positions = torch.arange(N_enc, dtype=torch.long).expand(batch_size, N_enc).to(self.device)\n",
    "\n",
    "        # input w/ linear + positional embedding\n",
    "        # input w/ linear = (batch_size, N_enc, model_dim) = (B, N_enc, D)\n",
    "        # embedded positions = (batch_size, N_enc, model_dim) = (B, N_enc, D)\n",
    "        out = self.dropout(self.linear(x) + self.position_embedding(positions))\n",
    "\n",
    "        # each encoder layer block\n",
    "        # out = (B, N_enc, D)\n",
    "        for layer in self.layers:\n",
    "            # value, key, query in encoder = out, out, out\n",
    "            out = layer(out, out, out)\n",
    "\n",
    "        # returns the output from last encoder block = (B, N_enc, D)\n",
    "        return out\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, model_dim, num_heads, forward_expansion, dropout):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.attention = SelfAttention(model_dim=model_dim, num_heads=num_heads)\n",
    "        self.norm = nn.LayerNorm(normalized_shape=model_dim)\n",
    "        self.encoder_block = EncoderBlock(\n",
    "            model_dim=model_dim, num_heads=num_heads, forward_expansion=forward_expansion, dropout=dropout\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, value, key, mask):\n",
    "        # Masked Multi-Head Attn. + Add & Norm Block\n",
    "        # x = (B, N_dec, D)\n",
    "        attention = self.attention(x, x, x, mask)\n",
    "        # query part for the encoder-decoder multi-head attention = (B, N_dec, D)\n",
    "        query = self.dropout(self.norm(attention + x))\n",
    "\n",
    "        # the encoder-decoder multi-head attention + add & norm + feed forward + add & norm\n",
    "        # is just an encoder block with value, key coming from enc_out, and query from masked MHA\n",
    "        # V, K = (B, N_enc, D), Q = (B, N_dec, D)\n",
    "        out = self.encoder_block(value, key, query)\n",
    "\n",
    "        # out = (B, N_dec, D)\n",
    "        return out\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            output_dim,\n",
    "            model_dim,\n",
    "            num_layers,\n",
    "            num_heads,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            n_dec,\n",
    "            device\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.linear = nn.Linear(in_features=n_dec, out_features=model_dim)\n",
    "        self.position_embedding = nn.Embedding(num_embeddings=n_dec, embedding_dim=model_dim)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                DecoderBlock(\n",
    "                    model_dim=model_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    forward_expansion=forward_expansion,\n",
    "                    dropout=dropout\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(in_features=model_dim, out_features=output_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, enc_out, mask):\n",
    "        # input, x = (batch_size, N_dec=1, num_features=3) = (B, N_dec, 3)\n",
    "        batch_size, N_dec, num_features = x.shape\n",
    "        # positions = (N_dec) -> (B, N_dec)\n",
    "        positions = torch.arange(N_dec, dtype=torch.long).expand(batch_size, N_dec).to(self.device)\n",
    "\n",
    "        # input w/ linear + positional embedding = (B, N_dec, D)\n",
    "        # input w/ linear = (batch_size, N_dec, model_dim) = (B, N_dec, D)\n",
    "        # embedded positions = (batch_size, N_dec, model_dim) = (B, N_dec, D)\n",
    "        out = self.dropout(self.linear(x) + self.position_embedding(positions))\n",
    "\n",
    "        for layer in self.layers:\n",
    "            # queries = input to decoder block, or output from prev decoder block\n",
    "            # keys, values = both are enc_out, that's why there's two, not a typo\n",
    "            # mask is for N_dec, N_dec masking\n",
    "            # out = (B, N_dec, D)\n",
    "            out = layer(out, enc_out, enc_out, mask)\n",
    "\n",
    "        # go from out = (B, N_dec, D) -> (B, N_dec, output_dim=1)\n",
    "        out = self.fc_out(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_dim=512,\n",
    "            num_layers=6,\n",
    "            forward_expansion=4,\n",
    "            num_heads=8,\n",
    "            dropout=0,\n",
    "            device='cuda',\n",
    "            n_enc=15,\n",
    "            n_dec=1,\n",
    "            num_features=3,\n",
    "            output_dim=1\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            model_dim=model_dim,\n",
    "            num_layers=num_layers,\n",
    "            num_heads=num_heads,\n",
    "            device=device,\n",
    "            forward_expansion=forward_expansion,\n",
    "            dropout=dropout,\n",
    "            n_enc=n_enc,\n",
    "            num_features=num_features\n",
    "        )\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "            output_dim=output_dim,\n",
    "            model_dim=model_dim,\n",
    "            num_layers=num_layers,\n",
    "            num_heads=num_heads,\n",
    "            forward_expansion=forward_expansion,\n",
    "            dropout=dropout,\n",
    "            n_dec=n_dec,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        self.device = device\n",
    "        \n",
    "        self.fc_out = nn.Sequential(\n",
    "            nn.Linear(output_dim, output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def make_mask(self, label):\n",
    "        # label = (B, N_dec, 1)\n",
    "        batch_size, N_dec, output_dim = label.shape\n",
    "\n",
    "        # mask = torch.ones((N_dec, N_dec)) = (N_dec, N_dec) matrix of 1s\n",
    "        # torch.tril(mask) = zeroes out everything about the diagonal of mask\n",
    "        # expands mask to (batch_size, num_heads, N_dec, N_dec) = (B, H, N_dec, N_dec)\n",
    "        mask = torch.tril(torch.ones((N_dec, N_dec))).expand(\n",
    "            batch_size, 1, N_dec, N_dec\n",
    "        )\n",
    "\n",
    "        return mask.to(self.device)\n",
    "\n",
    "    def forward(self, input_seq, label):\n",
    "        # input = (B=32, N_enc=15, num_features=3)\n",
    "        # label = (B=32, N_dec=1, output_dim=1)\n",
    "        mask = self.make_mask(label=label)\n",
    "        enc_out = self.encoder(input_seq)\n",
    "\n",
    "        # decoder takes\n",
    "        # label=input label, (B, N_dec, 1)\n",
    "        # enc_out=output from encoder, (B, N_enc, D)\n",
    "        # mask=mask, (B, H, N_dec, N_dec)\n",
    "        out = self.decoder(label, enc_out, mask)\n",
    "        out = self.fc_out(out)\n",
    "        # out = (B, N_dec, output_dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eed588-0a2f-466b-b9b8-2febb5f43bab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LSTM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89efd99-3c07-47a0-9407-b737ba4cfd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_layers, num_features, hidden_dim, dropout):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.num_features = num_features\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_features,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(\n",
    "            in_features=hidden_dim,\n",
    "            out_features=1\n",
    "            ),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, internal):\n",
    "        '''Computes the model forward pass\n",
    "        \n",
    "        Args:\n",
    "            x: The input sequence with shape (batch_size, seq_len, num_features)\n",
    "            internal: The initial internal states of the LSTM as a tuple (h_0, c_0)\n",
    "                both h_0 and c_0 have shape (num_layers, batch_size, hidden_size)\n",
    "        \n",
    "        Returns:\n",
    "            sales_pred: Normalized sales predictions for day after sequence across the batch\n",
    "            internal: Final hidden state and cell state for each layer as a tuple (h_n, c_n)\n",
    "                both h_n and c_n have shape (num_layers, batch_size, hidden_size)\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        # 1.) Input from DataLoader\n",
    "        # input: \n",
    "        #    xt = (batch_size, seq_len, num_features)\n",
    "        curr_batch_size = x.size(0)\n",
    "        \n",
    "        # 2.) LSTM Layer\n",
    "        # input: \n",
    "        #    xt = (batch_size, seq_len, num_features)\n",
    "        # output: \n",
    "        #    lstm_out = tensor of output features from the last layer of LSTM for each time step\n",
    "        #        tensor has shape (batch_size, seq_len, hidden_dim)\n",
    "        #    internal = internal hidden and cell states of nth LSTM layer, tuple of (h_n, c_n)\n",
    "        #        both h_c and c_n with shape (num_layers, batch_size, hidden_dim)\n",
    "        lstm_out, internal = self.lstm(x, internal)\n",
    "        \n",
    "        # 3.) Extract Next-Day Prediction\n",
    "        # input:\n",
    "        #    lstm_out = LSTM output for all time steps in the sequence\n",
    "        #        has shape (batch_size, seq_len, hidden_dim)\n",
    "        # output:\n",
    "        #    lstm_next = LSTM feature prediction for the day after the sequence\n",
    "        #        has shape (batch_size, hidden_dim)\n",
    "        lstm_next = lstm_out[:, -1, :]\n",
    "        \n",
    "        # 4.) Linear Layer\n",
    "        # input:\n",
    "        #    lstm_next = (batch_size, hidden_dim)\n",
    "        # output:\n",
    "        #    sales_pred = final predicted normalized sales value for day after sequence ends\n",
    "        #        has shape (batch_size, 1)\n",
    "        sales_pred = self.fc(lstm_next)\n",
    "        \n",
    "        return sales_pred, internal\n",
    "    \n",
    "    def init_internal_states(self, curr_batch_size):\n",
    "        '''Initializes hidden and cell states for the LSTM\n",
    "        \n",
    "        Args:\n",
    "            curr_batch_size: The size of the current batch in case we have uneven batches\n",
    "        \n",
    "        Returns:\n",
    "            internal = initial internal hidden and cell states for LSTM, tuple of (h_0, c_0)\n",
    "                both h_0 and c_0 with shape (num_layers, curr_batch_size, hidden_dim)\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        h_0 = torch.zeros((self.num_layers, curr_batch_size, self.hidden_dim), dtype=torch.float32).to(device)\n",
    "        c_0 = torch.zeros((self.num_layers, curr_batch_size, self.hidden_dim), dtype=torch.float32).to(device)\n",
    "        \n",
    "        internal = (h_0,c_0)\n",
    "        \n",
    "        return internal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be26166-7e8c-442e-9e60-c52dd5810d3b",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2666a005-72b8-465b-93bd-1199ee1abe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(architecture, model, train_loader, num_epochs, criterion, optimizer, scheduler):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            inputs, sales_target = batch\n",
    "            inputs = inputs.float().to(device) # inputs = (B, N_enc, 3)\n",
    "            \n",
    "            if architecture == 'transformer': # sales_target = (B, N_dec, 3)\n",
    "                sales_target = sales_target.float().unsqueeze(1).unsqueeze(2).to(device)\n",
    "                \n",
    "                out = model(inputs, sales_target)\n",
    "                sales_pred = out[:, -1, :].squeeze(-1)\n",
    "                \n",
    "            elif architecture == 'lstm': # sales_target = ()\n",
    "                sales_target = sales_target.float().to(device)\n",
    "                                \n",
    "                # initializes hidden and cell states with current batch_size\n",
    "                internal = model.init_internal_states(inputs.size(0))\n",
    "                internal = tuple(i.detach() for i in internal)\n",
    "                \n",
    "                sales_pred, internal = model(inputs, internal)\n",
    "\n",
    "            loss = criterion(sales_pred, sales_target)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "            if batch_idx == len(train_loader) - 1:        \n",
    "                progress = 100. * batch_idx / len(train_loader)\n",
    "                print(f'Train(Epoch {epoch})[{progress:.0f}%]: Loss: {train_loss / (batch_idx + 1):.4f}')\n",
    "        \n",
    "        scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71979b92-bae7-4995-8675-7d7c00115875",
   "metadata": {},
   "source": [
    "# Predicting Testing Values Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f266374-5d55-4894-b194-0aa7764c236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sales(architecture, model, store_nbr, family, current_seq, norm_values, subset_test_data, test_df):\n",
    "    # Predict sales values for testing dates\n",
    "    model.eval()\n",
    "    \n",
    "    if architecture == 'lstm':\n",
    "        internal = model.init_internal_states(1)\n",
    "\n",
    "    for date in subset_test_data.index:\n",
    "        with torch.no_grad():\n",
    "            # turns (15, 3) sequence into (1, 15, 3) Tensor for batch dimension\n",
    "            current_seq_input = torch.Tensor(current_seq).float().unsqueeze(0).to(device)\n",
    "            label = torch.zeros(1, 1, 1).float().to(device)\n",
    "            \n",
    "            if architecture == 'transformer':\n",
    "                out = model(current_seq_input, label)\n",
    "                sales_pred = out[:, -1, :].squeeze(-1)\n",
    "                sales_pred = sales_pred.cpu().numpy() # Get the scalar prediction\n",
    "            elif architecture == 'lstm':\n",
    "                sales_pred, _ = model(current_seq_input, internal)\n",
    "                sales_pred = sales_pred.cpu().numpy().flatten()[0]  # Get the scalar prediction\n",
    "\n",
    "            # updates the testing date's sales number from 0 to the predicted value\n",
    "            # takes that date's row as the \"next day\", this is a (1, 3) np array\n",
    "            subset_test_data.loc[date, 'sales'] = sales_pred\n",
    "            next_day = subset_test_data.loc[date].values\n",
    "\n",
    "            # updates the current (15, 3) sequence to shift over 1 in time\n",
    "            new_seq = np.vstack((current_seq, next_day))\n",
    "            current_seq = new_seq[1:]\n",
    "\n",
    "    # Unnormalize the testing data\n",
    "    for col in subset_test_data.columns:\n",
    "        mn, mx = norm_values[col]\n",
    "        subset_test_data[col] = subset_test_data[col] * (mx - mn) + mn\n",
    "    \n",
    "    # Create dataframe of ID mapped to predicted sales values for this store_nbr, family pair\n",
    "    subset_test_data = subset_test_data.reset_index().rename(columns={'index': 'date'})\n",
    "    filtered_test_df = test_df[(test_df['store_nbr'] == store_nbr) & (test_df['family'] == family)]\n",
    "    merged_df = filtered_test_df.reset_index().merge(subset_test_data, on='date', how='left')\n",
    "\n",
    "    predicted_values = merged_df[['id', 'sales']].copy()\n",
    "    predicted_values.rename(columns={'id': 'ID', 'sales': 'Sales'}, inplace=True)\n",
    "        \n",
    "    return predicted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd026462-211c-4e82-9dbd-80218836dad2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e54f2-7e6b-4e46-909f-15acc404a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(architecture, all_preds):\n",
    "    total_df = pd.concat(all_preds, ignore_index=True)\n",
    "    total_df = total_df.sort_values(by='ID', ignore_index=True)\n",
    "    print(total_df)\n",
    "    total_df.columns = ['id', 'sales']\n",
    "    total_df.to_csv(f'submission_{architecture}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dfe24a-f3b5-4126-a698-4374d57d7a9a",
   "metadata": {},
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ec502-734d-4ed7-9128-853ce8a8c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = ['transformer', 'lstm']\n",
    "\n",
    "for architecture in architectures:\n",
    "    all_preds = []\n",
    "    \n",
    "    for store_nbr in store_nbrs:\n",
    "        \n",
    "        counter = 0\n",
    "        for family in families:\n",
    "            \n",
    "            counter += 1\n",
    "            # Create subset of training & testing data and then normalize\n",
    "            _, subset_train_df = create_subset(store_nbr=store_nbr, family=family, df=train_df)\n",
    "            testing_dates, subset_test_data = create_subset(store_nbr=store_nbr, family=family, df=test_df)\n",
    "            \n",
    "            # Store normalize values across training data to later unnormalize with\n",
    "            norm_values = {}\n",
    "            for col in subset_train_df:\n",
    "                mn, mx = subset_train_df[col].min(), subset_train_df[col].max()\n",
    "                norm_values[col] = (mn, mx)\n",
    "                if mx != mn:\n",
    "                    subset_train_df[col] = (subset_train_df[col] - mn) / (mx - mn)\n",
    "                    subset_test_data[col] = (subset_test_data[col] - mn) / (mx - mn)\n",
    "\n",
    "            # Create sequences from training subset and make DataLoader\n",
    "            X, y = create_sequences(df=subset_train_df)\n",
    "            train_data = TensorDataset(torch.from_numpy(X), torch.from_numpy(y.astype('float32')))\n",
    "            train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "            # Make model\n",
    "            \n",
    "            if architecture == 'transformer': \n",
    "                model = Transformer(\n",
    "                    model_dim=model_dim,\n",
    "                    num_layers=6,\n",
    "                    forward_expansion=forward_expansion,\n",
    "                    num_heads=num_heads,\n",
    "                    dropout=dropout,\n",
    "                    device=device,\n",
    "                    n_enc=n_enc,\n",
    "                    n_dec=n_dec,\n",
    "                    num_features=3,\n",
    "                    output_dim=output_dim\n",
    "                ).to(device)\n",
    "\n",
    "            elif architecture == 'lstm':\n",
    "                model = LSTM(\n",
    "                    num_layers=num_layers, \n",
    "                    num_features=num_features, \n",
    "                    hidden_dim=hidden_dim, \n",
    "                    dropout=dropout\n",
    "                ).to(device)\n",
    "\n",
    "            print(model)\n",
    "            criterion = RMSLELoss().to(device)\n",
    "            optimizer = make_optimizer(optimizer_name, model, lr=lr, momentum=0, weight_decay=0)\n",
    "            scheduler = make_scheduler(scheduler_name, optimizer, milestones=[5], factor=0.1)\n",
    "\n",
    "            # Train\n",
    "            train(\n",
    "                architecture=architecture,\n",
    "                model=model, \n",
    "                train_loader=train_loader, \n",
    "                num_epochs=num_epochs, \n",
    "                criterion=criterion, \n",
    "                optimizer=optimizer, \n",
    "                scheduler=scheduler\n",
    "            )\n",
    "\n",
    "            # Predict on Testing Data\n",
    "            id_to_sales = predict_sales(\n",
    "                architecture=architecture,\n",
    "                model=model, \n",
    "                store_nbr=store_nbr, \n",
    "                family=family, \n",
    "                current_seq=X[-1], \n",
    "                norm_values=norm_values, \n",
    "                subset_test_data=subset_test_data, \n",
    "                test_df=test_df\n",
    "            )\n",
    "\n",
    "            all_preds.append(id_to_sales)\n",
    "    \n",
    "    save_submission(architecture=architecture, all_preds=all_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
